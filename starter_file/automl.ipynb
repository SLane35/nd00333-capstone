{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1610997495492
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "# choose a name for experiment\n",
        "experiment_name = 'labor-prediction-experiment'\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1610997501919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core import Dataset, Datastore\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "datastore_name='workspaceblobstore'\n",
        "datastore=Datastore.get(ws,datastore_name)\n",
        "\n",
        "datastore_path = [(datastore, 'UI/01-18-2021_062839_UTC/LaborPredictionData6.csv')]\n",
        "ds = Dataset.Tabular.from_delimited_files(path=datastore_path)\n",
        "\n",
        "ds = ds.take(3000).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1610997532162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "# Use the clean_data function to clean your data.\n",
        "x, y = clean_data(ds)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.8)\n",
        "\n",
        "#y_train=y_train.reshape(1728, 1)\n",
        "#train = np.concatenate((x_train,y_train), axis=1)\n",
        "train=pd.concat([x_train, y_train], axis=1)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1610997577052
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task='regression',\n",
        "    primary_metric='r2_score',\n",
        "    training_data=train,\n",
        "    label_column_name='TotalInstallationTime',\n",
        "    n_cross_validations=10)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1610997621496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No run_configuration provided, running on local with default configuration\n",
            "Running on local machine\n",
            "Parent Run ID: AutoML_6860d557-fcd4-4792-92b8-d827986df787\n",
            "\n",
            "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
            "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
            "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:29       0.2231    0.2231\n",
            "         1   MaxAbsScaler XGBoostRegressor                  0:00:25       0.2545    0.2545\n",
            "         2   SparseNormalizer XGBoostRegressor              0:00:35       0.2212    0.2545\n",
            "         3   MaxAbsScaler RandomForest                      0:00:38       0.2534    0.2545\n",
            "         4   StandardScalerWrapper XGBoostRegressor         0:00:29       0.1991    0.2545\n",
            "         5   MaxAbsScaler ElasticNet                        0:00:22       0.2629    0.2629\n",
            "         6   MinMaxScaler RandomForest                      0:00:42       0.2379    0.2629\n",
            "         7   StandardScalerWrapper XGBoostRegressor         0:00:28       0.2095    0.2629\n",
            "         8   MinMaxScaler ExtremeRandomTrees                0:00:30       0.2355    0.2629\n",
            "         9   StandardScalerWrapper ElasticNet               0:00:25       0.2652    0.2652\n",
            "        10   MinMaxScaler RandomForest                      0:00:45       0.2568    0.2652\n",
            "        11   MinMaxScaler RandomForest                      0:00:24       0.2397    0.2652\n",
            "        12   StandardScalerWrapper XGBoostRegressor         0:00:25       0.2160    0.2652\n",
            "        13   RobustScaler LassoLars                         0:00:24       0.2629    0.2652\n",
            "        14   MinMaxScaler ExtremeRandomTrees                0:00:24       0.2123    0.2652\n",
            "        15   MaxAbsScaler ExtremeRandomTrees                0:00:24       0.1949    0.2652\n",
            "        16   MinMaxScaler ExtremeRandomTrees                0:00:29       0.2418    0.2652\n",
            "        17   MaxAbsScaler ElasticNet                        0:00:23       0.2646    0.2652\n",
            "        18   MinMaxScaler RandomForest                      0:00:24       0.1801    0.2652\n",
            "        19   MaxAbsScaler RandomForest                      0:00:24       0.2318    0.2652\n",
            "        20   RobustScaler ElasticNet                        0:00:25       0.2660    0.2660\n",
            "        21   StandardScalerWrapper RandomForest             0:00:29       0.2460    0.2660\n",
            "        22   RobustScaler LightGBM                          0:00:29       0.1904    0.2660\n",
            "        23   RobustScaler ExtremeRandomTrees                0:06:23       0.2533    0.2660\n",
            "        24   MaxAbsScaler RandomForest                      0:00:31       0.2240    0.2660\n",
            "        25   PCA ElasticNet                                 0:00:30      -0.0092    0.2660\n",
            "        26   StandardScalerWrapper DecisionTree             0:00:29       0.1445    0.2660\n",
            "        27   MinMaxScaler RandomForest                      0:00:25       0.2455    0.2660\n",
            "        28   RobustScaler RandomForest                      0:00:31       0.2582    0.2660\n",
            "        29   MinMaxScaler RandomForest                      0:00:38       0.2002    0.2660\n",
            "        30   RobustScaler ElasticNet                        0:00:24       0.0464    0.2660\n",
            "        31   StandardScalerWrapper ElasticNet               0:00:27       0.2626    0.2660\n",
            "        32   "
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1610648489052
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610648489267
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_mlrun, fitted_mlmodel = remote_run.get_output()\r\n",
        "print(best_mlrun)\r\n",
        "print(fitted_mlmodel)\r\n",
        "joblib.dump(fitted_mlmodel, \"automlmodel.pkl\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610648490368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#register the model\r\n",
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.model import Model\r\n",
        "\r\n",
        "description = 'Best AutoML Model'\r\n",
        "#model = best_mlrun.register_model(description=description, workspace = , model_name='automl_pred', model_path='./models')\r\n",
        "model = Model.register(model_path=\"automlmodel.pkl\", model_name = \"automl_pred\", description=description, workspace=ws)\r\n",
        "print(model.name, model.id, model.version, sep='\\t')\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610648492478
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define inference config\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#create the environment\r\n",
        "myenv = Environment(name=\"myenv\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "\r\n",
        "#Define the packages needed by the model and scripts\r\n",
        "conda_dep.add_conda_package(\"tensorflow\")\r\n",
        "conda_dep.add_conda_package(\"numpy\")\r\n",
        "conda_dep.add_conda_package(\"scikit-learn\")\r\n",
        "conda_dep.add_conda_package(\"py-xgboost\")\r\n",
        "#You must list azureml-defaults as a pip dependency\r\n",
        "conda_dep.add_pip_package(\"azureml-defaults\")\r\n",
        "conda_dep.add_pip_package(\"keras\")\r\n",
        "conda_dep.add_pip_package(\"gensim\")\r\n",
        "conda_dep.add_pip_package(\"azureml-automl-core\")\r\n",
        "conda_dep.add_pip_package(\"azureml-automl-runtime\")\r\n",
        "conda_dep.add_pip_package(\"packaging\")\r\n",
        "\r\n",
        "\r\n",
        "myenv.python.conda_dependencies=conda_dep\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610648492600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deploy as webservice\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "from azureml.train.automl import *\r\n",
        "\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=True, enable_app_insights=True)\r\n",
        "#deployment_config = LocalWebservice.deploy_configuration()\r\n",
        "\r\n",
        "model = Model(ws, name='automl_pred')\r\n",
        "print(model)\r\n",
        "service = Model.deploy(ws, 'laborpredservice', [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.get_logs)\r\n",
        "print(service.state)\r\n",
        "print(\"scoring URI: \" + service.scoring_uri)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610649804867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#send request\r\n",
        "\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from pandas import DataFrame\r\n",
        "\r\n",
        "scoring_uri = service.scoring_uri\r\n",
        "key = 'xlEe0aHu7gegnAEgyATae6cGEAEfhMp6'\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key}\r\n",
        "#test_data = json.dumps({'data': [{'heightwholenum':67, 'framemat':'ALUMINUM', 'framefunc':'DOOR', 'widthWholeNum':24, 'lift':0, 'itemset':'SNAP BEADS', 'locationtype':9, 'leadmechanic':118}]})\r\n",
        "#data = json.loads([67, 'ALUMINUM', 'DOOR', 24, 0, 'SNAP BEADS', 9, 118])['data']\r\n",
        "#['heightwholenum','widthWholeNum','lift','LongCarry', \r\n",
        "#'itemset_','itemset_OTHER', 'itemset_PRESSURE PLATE','itemset_PUTTY','itemset_SCREW BEADS','itemset_SNAP BEADS','itemset_VINYL BEADS', 'itemset_WOOD BEADS','itemset_WRAP AROUND FRAME','itemset_WRAP AROUND RUBBER',\r\n",
        "#'itemset_flush glaze', 'leadmechanic_6','leadmechanic_11','leadmechanic_62','leadmechanic_90','leadmechanic_118','leadmechanic_211', 'leadmechanic_228','leadmechanic_OTHER',\r\n",
        "#'locationtype_0','locationtype_1','locationtype_2','locationtype_4','locationtype_5','locationtype_6','locationtype_7','locationtype_9','locationtype_10','locationtype_11','locationtype_12', 'locationtype_13',\r\n",
        "#'framemat_','framemat_ALUMINUM','framemat_ANDERSEN','framemat_OTHER','framemat_SASH RAIL','framemat_VINYL','framemat_WOOD','framefunc_BOTTOM DH','framefunc_BOTTOM SH', 'framefunc_CASEMENT', \r\n",
        "#'framefunc_CURTAIN WALL', 'framefunc_FIXED','framefunc_FLUSH GLAZE', 'framefunc_OTHER', 'framefunc_SASH', 'framefunc_SIDELITE', 'framefunc_SLIDER','framefunc_TOP DH', 'framefunc_TOP SH','framefunc_TRANSOM']]\r\n",
        "    \r\n",
        "input_string = {'data':[{\"heightwholenum\":67,\"widthWholeNum\":24,\"lift\":0,\"LongCarry\":0,\"itemset_\":0,\"itemset_OTHER\":0,\"itemset_PRESSURE PLATE\":0,\"itemset_PUTTY\":0,\"itemset_SCREW BEADS\":0,\"itemset_SNAP BEADS\":1,\r\n",
        "\"itemset_VINYL BEADS\":0,\"itemset_WOOD BEADS\":0,\"itemset_WRAP AROUND FRAME\":0,\"itemset_WRAP AROUND RUBBER\":0,\"itemset_flush glaze\":0,\"leadmechanic_6\":0,\"leadmechanic_11\":0,\"leadmechanic_62\":0,\"leadmechanic_90\":0,\r\n",
        "\"leadmechanic_118\":1,\"leadmechanic_211\":0,\"leadmechanic_228\":0,\"leadmechanic_OTHER\":0,\"locationtype_0\":0,\"locationtype_1\":0,\"locationtype_2\":0,\"locationtype_4\":0,\"locationtype_5\":0,\"locationtype_6\":0,\r\n",
        "\"locationtype_7\":0,\"locationtype_9\":1,\"locationtype_10\":0,\"locationtype_11\":0,\"locationtype_12\":0,\"locationtype_13\":0,\"framemat_\":0,\"framemat_ALUMINUM\":1,\"framemat_ANDERSEN\":0,\"framemat_OTHER\":0,\r\n",
        "\"framemat_SASH RAIL\":0,\"framemat_VINYL\":0,\"framemat_WOOD\":0,\"framefunc_BOTTOM DH\":0,\"framefunc_BOTTOM SH\":0,\"framefunc_CASEMENT\":0,\"framefunc_CURTAIN WALL\":0,\"framefunc_FIXED\":0,\"framefunc_FLUSH GLAZE\":0,\r\n",
        "\"framefunc_OTHER\":0,\"framefunc_SASH\":0,\"framefunc_SIDELITE\":0,\"framefunc_SLIDER\":0,\"framefunc_TOP DH\":0,\"framefunc_TOP SH\":0,\"framefunc_TRANSOM\":0}]}\r\n",
        "data = json.dumps(input_string)\r\n",
        "\r\n",
        "#data = \"{\\\"data\\\": [\" + str(list(input_string)) + \"]}\"\r\n",
        "#data = json.dumps(np.array(input_string).tolist())\r\n",
        "#data = pd.DataFrame.from_dict(data)\r\n",
        "\r\n",
        "response = requests.post(scoring_uri, data=data, headers=headers)\r\n",
        "print(response.status_code)\r\n",
        "print(response.elapsed)\r\n",
        "print(response.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610649955466
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}