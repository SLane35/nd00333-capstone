{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive import BayesianParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice\n",
        "\n",
        "from azureml.core import Dataset, Datastore\n",
        "from azureml.data.datapath import DataPath\n",
        "import os\n",
        "import joblib"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1610916656188
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.get(name=\"quick-starts-ws-135109\")\n",
        "exp = Experiment(workspace=ws, name=\"labor-prediction-experiment\")\n",
        "\n",
        "run = exp.start_logging\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1610916656714
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore_name='workspaceblobstore'\r\n",
        "datastore=Datastore.get(ws,datastore_name)\r\n",
        "\r\n",
        "datastore_path = [(datastore, 'UI/01-17-2021_061017_UTC/LaborPredictionData6.csv')]\r\n",
        "ds = Dataset.Tabular.from_delimited_files(path=datastore_path)\r\n",
        "\r\n",
        "ds = ds.take(3000).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610916661310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cluster_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_D2_V2\", max_nodes=4)\r\n",
        "compute_cluster = ComputeTarget.create(ws, \"compute-cluster\", compute_cluster_config)\r\n",
        "\r\n",
        "compute_cluster.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610916682071
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "#early_termination_policy = <your policy here>\n",
        "\n",
        "#TODO: Create the different params that you will be using during training\n",
        "param_sampling = BayesianParameterSampling( {\n",
        "    '--fit_intercept': choice(1,0),\n",
        "    '--normalize': choice(1,0)\n",
        "})\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "    \n",
        "#TODO: Create your estimator and hyperdrive config\n",
        "est = SKLearn(source_directory=\".\", compute_target=compute_cluster, entry_script='train.py')\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(hyperparameter_sampling=param_sampling, primary_metric_name=\"r2\", primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, max_total_runs=5, max_concurrent_runs=3, estimator=est )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n",
            "For best results with Bayesian Sampling we recommend using a maximum number of runs greater than or equal to 20 times the number of hyperparameters being tuned. Recommendend value:40.\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1610916682276
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(config=hyperdrive_run_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1610916688753
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(run).show()\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef61d135842f4d309963d269eb38058f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/labor-prediction-experiment/runs/HD_f92c8594-deb1-4885-a81c-ec185139a573?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-135109/workspaces/quick-starts-ws-135109\", \"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573\", \"run_properties\": {\"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573\", \"created_utc\": \"2021-01-17T20:51:27.675617Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"r2\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"e73f72cb-fc39-4815-a586-91c24ff92d98\", \"score\": \"0.31463998532503445\", \"best_child_run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_3\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"3\", \"max_concurrent_jobs\": \"3\", \"_aml_system_max_total_jobs\": \"5\", \"max_total_jobs\": \"5\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--fit_intercept\\\": [\\\"choice\\\", [[1, 0]]], \\\"--normalize\\\": [\\\"choice\\\", [[1, 0]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"--fit_intercept\\\": [\\\"choice\\\", [[1, 0]]], \\\"--normalize\\\": [\\\"choice\\\", [[1, 0]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"r2\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"r2\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourceGroups/aml-quickstarts-135109/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-135109/experiments/labor-prediction-experiment\\\", \\\"SubscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-135109\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-135109\\\", \\\"ExperimentName\\\": \\\"labor-prediction-experiment\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"compute-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"e73f72cb-fc39-4815-a586-91c24ff92d98\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"f873a0bd-b12b-4fbf-8195-e2e3489c0911\\\", \\\"amlClientSessionId\\\": \\\"c19fb8d2-c912-430d-a36c-aea6643d354a\\\", \\\"subscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 3, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourceGroups/aml-quickstarts-135109/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-135109/experiments/labor-prediction-experiment\\\", \\\"SubscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-135109\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-135109\\\", \\\"ExperimentName\\\": \\\"labor-prediction-experiment\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"compute-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"e73f72cb-fc39-4815-a586-91c24ff92d98\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"f873a0bd-b12b-4fbf-8195-e2e3489c0911\\\", \\\"amlClientSessionId\\\": \\\"c19fb8d2-c912-430d-a36c-aea6643d354a\\\", \\\"subscriptionId\\\": \\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 3, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-01-17T20:51:28.515842\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-01-17T20:51:28.515842\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"42492d67ad72e70da7c5dc20686dc09e414fd9ab6ae25a7c4bbbb503e4057a64\\\"\", \"progress_metadata_digest\": \"\\\"42492d67ad72e70da7c5dc20686dc09e414fd9ab6ae25a7c4bbbb503e4057a64\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-01-17T20:51:28.515842\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-01-17T20:51:28.515842\\\"\", \"_aml_system_HD_f92c8594-deb1-4885-a81c-ec185139a573_0\": \"{\\\"--fit_intercept\\\": 0, \\\"--normalize\\\": 0}\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_0\": \"{\\\"--fit_intercept\\\": 0, \\\"--normalize\\\": 0}\", \"_aml_system_HD_f92c8594-deb1-4885-a81c-ec185139a573_1\": \"{\\\"--fit_intercept\\\": 0, \\\"--normalize\\\": 1}\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_1\": \"{\\\"--fit_intercept\\\": 0, \\\"--normalize\\\": 1}\", \"_aml_system_HD_f92c8594-deb1-4885-a81c-ec185139a573_2\": \"{\\\"--fit_intercept\\\": 1, \\\"--normalize\\\": 1}\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_2\": \"{\\\"--fit_intercept\\\": 1, \\\"--normalize\\\": 1}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_preparation\", \"prepare_run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_preparation\", \"_aml_system_HD_f92c8594-deb1-4885-a81c-ec185139a573_3\": \"{\\\"--fit_intercept\\\": 1, \\\"--normalize\\\": 0}\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_3\": \"{\\\"--fit_intercept\\\": 1, \\\"--normalize\\\": 0}\"}, \"end_time_utc\": \"2021-01-17T21:04:25.658283Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg135109.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_f92c8594-deb1-4885-a81c-ec185139a573/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=LYayRe7d0UuqAo68qgGcu%2F0sUy09D51uzkDZmvrwbOg%3D&st=2021-01-17T20%3A54%3A46Z&se=2021-01-18T05%3A04%3A46Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:12:57\", \"hyper_parameters\": {\"--fit_intercept\": [\"choice\", [[1, 0]]], \"--normalize\": [\"choice\", [[1, 0]]]}}, \"child_runs\": [{\"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_0\", \"run_number\": 132, \"metric\": 0.27733512, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-17T20:55:50.108908Z\", \"end_time\": \"2021-01-17T20:59:49.264073Z\", \"created_time\": \"2021-01-17T20:52:01.207344Z\", \"created_time_dt\": \"2021-01-17T20:52:01.207344Z\", \"duration\": \"0:07:48\", \"hyperdrive_id\": \"f92c8594-deb1-4885-a81c-ec185139a573\", \"arguments\": null, \"param_--fit_intercept\": 0, \"param_--normalize\": 0, \"best_metric\": 0.27733512}, {\"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_2\", \"run_number\": 133, \"metric\": 0.29071411, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-17T20:55:29.803517Z\", \"end_time\": \"2021-01-17T20:59:43.879392Z\", \"created_time\": \"2021-01-17T20:52:01.495591Z\", \"created_time_dt\": \"2021-01-17T20:52:01.495591Z\", \"duration\": \"0:07:42\", \"hyperdrive_id\": \"f92c8594-deb1-4885-a81c-ec185139a573\", \"arguments\": null, \"param_--fit_intercept\": 1, \"param_--normalize\": 1, \"best_metric\": 0.29071411}, {\"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_1\", \"run_number\": 134, \"metric\": 0.16870056, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-17T20:55:33.105601Z\", \"end_time\": \"2021-01-17T20:59:55.735593Z\", \"created_time\": \"2021-01-17T20:52:01.57891Z\", \"created_time_dt\": \"2021-01-17T20:52:01.57891Z\", \"duration\": \"0:07:54\", \"hyperdrive_id\": \"f92c8594-deb1-4885-a81c-ec185139a573\", \"arguments\": null, \"param_--fit_intercept\": 0, \"param_--normalize\": 1, \"best_metric\": 0.29071411}, {\"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573_3\", \"run_number\": 135, \"metric\": 0.31463999, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-01-17T21:00:22.427628Z\", \"end_time\": \"2021-01-17T21:03:52.762965Z\", \"created_time\": \"2021-01-17T21:00:11.257345Z\", \"created_time_dt\": \"2021-01-17T21:00:11.257345Z\", \"duration\": \"0:03:41\", \"hyperdrive_id\": \"f92c8594-deb1-4885-a81c-ec185139a573\", \"arguments\": null, \"param_--fit_intercept\": 1, \"param_--normalize\": 0, \"best_metric\": 0.31463999}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Fit Intercept:\": [{\"categories\": [132, 133, 134, 135], \"mode\": \"markers\", \"name\": \"Fit Intercept:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [true, true, true, true]}, {\"categories\": [132, 133, 134, 135], \"mode\": \"lines\", \"name\": \"Fit Intercept:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [true, true, true, true]}], \"Normalize:\": [{\"categories\": [132, 133, 134, 135], \"mode\": \"markers\", \"name\": \"Normalize:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [true, true, true, true]}, {\"categories\": [132, 133, 134, 135], \"mode\": \"lines\", \"name\": \"Normalize:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [true, true, true, true]}], \"r2\": [{\"categories\": [132, 133, 134, 135], \"mode\": \"markers\", \"name\": \"r2\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.27733511630415575, 0.2907141056499286, 0.16870055952049645, 0.31463998532503445]}, {\"categories\": [132, 133, 134, 135], \"mode\": \"lines\", \"name\": \"r2_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.27733511630415575, 0.2907141056499286, 0.2907141056499286, 0.31463998532503445]}]}, \"metricName\": null, \"primaryMetricName\": \"r2\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_f92c8594-deb1-4885-a81c-ec185139a573\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"r2\", \"r2\", \"r2\", \"r2\"], \"timestamp\": [\"2021-01-17 20:58:33.705371+00:00\", \"2021-01-17 20:59:04.732139+00:00\", \"2021-01-17 21:02:12.446510+00:00\", \"2021-01-17 21:02:12.446510+00:00\"], \"run_id\": [\"HD_f92c8594-deb1-4885-a81c-ec185139a573_1\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_2\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_3\", \"HD_f92c8594-deb1-4885-a81c-ec185139a573_3\"], \"metric_value\": [0.16870055952049645, 0.2907141056499286, 0.31463998532503445, 0.31463998532503445], \"final\": [false, false, false, true]}]}]}], \"run_logs\": \"[2021-01-17T20:51:28.208333][API][INFO]Experiment created\\r\\n[2021-01-17T20:51:28.634090][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2021-01-17T20:51:28.819328][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2021-01-17T20:51:29.4191351Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-01-17T20:52:00.4667026Z][SCHEDULER][INFO]Scheduling job, id='HD_f92c8594-deb1-4885-a81c-ec185139a573_0'\\r\\n[2021-01-17T20:52:00.4661892Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-01-17T20:52:00.4677184Z][SCHEDULER][INFO]Scheduling job, id='HD_f92c8594-deb1-4885-a81c-ec185139a573_1'\\r\\n[2021-01-17T20:52:01.4344557Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_f92c8594-deb1-4885-a81c-ec185139a573_0'\\r\\n[2021-01-17T20:52:00.4688795Z][SCHEDULER][INFO]Scheduling job, id='HD_f92c8594-deb1-4885-a81c-ec185139a573_2'\\r\\n[2021-01-17T20:52:01.6513309Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_f92c8594-deb1-4885-a81c-ec185139a573_2'\\r\\n[2021-01-17T20:52:01.6970025Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_f92c8594-deb1-4885-a81c-ec185139a573_1'\\r\\n[2021-01-17T20:59:59.701435][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2021-01-17T20:59:59.982187][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-01-17T21:00:10.4187975Z][SCHEDULER][INFO]Scheduling job, id='HD_f92c8594-deb1-4885-a81c-ec185139a573_3'\\r\\n[2021-01-17T21:00:11.3582046Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_f92c8594-deb1-4885-a81c-ec185139a573_3'\\r\\n[2021-01-17T21:00:29.993244][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-01-17T21:00:30.446599][GENERATOR][WARNING]Could not sample any more jobs from the space.\\r\\n[2021-01-17T21:04:26.133811][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_f92c8594-deb1-4885-a81c-ec185139a573\n",
            "Web View: https://ml.azure.com/experiments/labor-prediction-experiment/runs/HD_f92c8594-deb1-4885-a81c-ec185139a573?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-135109/workspaces/quick-starts-ws-135109\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-01-17T20:51:28.208333][API][INFO]Experiment created<END>\\n\"\"<START>[2021-01-17T20:51:28.634090][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-01-17T20:51:28.819328][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2021-01-17T20:51:29.4191351Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: HD_f92c8594-deb1-4885-a81c-ec185139a573\n",
            "Web View: https://ml.azure.com/experiments/labor-prediction-experiment/runs/HD_f92c8594-deb1-4885-a81c-ec185139a573?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-135109/workspaces/quick-starts-ws-135109\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "{'runId': 'HD_f92c8594-deb1-4885-a81c-ec185139a573',\n 'target': 'compute-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2021-01-17T20:51:27.932615Z',\n 'endTimeUtc': '2021-01-17T21:04:25.658283Z',\n 'properties': {'primary_metric_config': '{\"name\": \"r2\", \"goal\": \"maximize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': 'e73f72cb-fc39-4815-a586-91c24ff92d98',\n  'score': '0.31463998532503445',\n  'best_child_run_id': 'HD_f92c8594-deb1-4885-a81c-ec185139a573_3',\n  'best_metric_status': 'Succeeded'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg135109.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_f92c8594-deb1-4885-a81c-ec185139a573/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=LYayRe7d0UuqAo68qgGcu%2F0sUy09D51uzkDZmvrwbOg%3D&st=2021-01-17T20%3A54%3A46Z&se=2021-01-18T05%3A04%3A46Z&sp=r'}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1610917525799
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = run.get_best_run_by_primary_metric()\n",
        "print(best_run)\n",
        "print(type(best_run))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: labor-prediction-experiment,\n",
            "Id: HD_f92c8594-deb1-4885-a81c-ec185139a573_3,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed)\n",
            "<class 'azureml.core.run.Run'>\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1610917526086
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the best model\n",
        "#best_run.upload_file(\"outputs/bestmodel.pkl\", \"outputs/bestmodel.pkl\")\n",
        "model = best_run.register_model(model_name='bestmodel.pkl', model_path='.')\n",
        "#model = best_run.register_model(model_name='hyperdrivemodel', model_path='.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1610917657794
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define inference config\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#create the environment\r\n",
        "myenv = Environment(name=\"myenv\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "\r\n",
        "#Define the packages needed by the model and scripts\r\n",
        "conda_dep.add_conda_package(\"tensorflow\")\r\n",
        "conda_dep.add_conda_package(\"numpy\")\r\n",
        "conda_dep.add_conda_package(\"scikit-learn\")\r\n",
        "conda_dep.add_conda_package(\"py-xgboost\")\r\n",
        "#You must list azureml-defaults as a pip dependency\r\n",
        "conda_dep.add_pip_package(\"azureml-defaults\")\r\n",
        "conda_dep.add_pip_package(\"keras\")\r\n",
        "conda_dep.add_pip_package(\"gensim\")\r\n",
        "conda_dep.add_pip_package(\"azureml-automl-core\")\r\n",
        "conda_dep.add_pip_package(\"azureml-automl-runtime\")\r\n",
        "conda_dep.add_pip_package(\"packaging\")\r\n",
        "#conda_dep.save_to_file(base_directory='./', conda_file_path='myenv.yml')\r\n",
        "#myenv = Environment.from_conda_specification(name='myenv', file_path='myenv.yml')\r\n",
        "myenv.python.conda_dependencies=conda_dep\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1610917668464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deploy as webservice\r\n",
        "#from azureml.core.webservice import AciWebservice\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "from azureml.core.webservice import Webservice\r\n",
        "from azureml.train.automl import *\r\n",
        "\r\n",
        "#deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, auth_enabled=True, enable_app_insights=True)\r\n",
        "deployment_config = LocalWebservice.deploy_configuration()\r\n",
        "\r\n",
        "#model = Model(ws, name='hyperdrive_pred')\r\n",
        "print(model)\r\n",
        "service = Model.deploy(ws, 'hyperdrivelaborpredservice2', [model], inference_config, deployment_config)\r\n",
        "\r\n",
        "service.wait_for_deployment(True)\r\n",
        "print(service.get_logs)\r\n",
        "print(service.state)\r\n",
        "print(\"scoring URI: \" + service.scoring_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(workspace=Workspace.create(name='quick-starts-ws-135109', subscription_id='3e42d11f-d64d-4173-af9b-12ecaa1030b3', resource_group='aml-quickstarts-135109'), name=bestmodel.pkl, id=bestmodel.pkl:7, version=7, tags={}, properties={})\n",
            "Downloading model bestmodel.pkl:7 to /tmp/azureml_cvrj1q99/bestmodel.pkl/7\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            "Generating Docker build context.\n",
            "Package creation Succeeded\n",
            "Logging into Docker registry 2d66eb9071cf44db91e300274c963aad.azurecr.io\n",
            "Logging into Docker registry 2d66eb9071cf44db91e300274c963aad.azurecr.io\n",
            "Building Docker image from Dockerfile...\n",
            "Step 1/5 : FROM 2d66eb9071cf44db91e300274c963aad.azurecr.io/azureml/azureml_961f3263ef1e499c1ed57f2f56689580\n",
            " ---> 2d72eadf5e6b\n",
            "Step 2/5 : COPY azureml-app /var/azureml-app\n",
            " ---> eaab89c75feb\n",
            "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjNlNDJkMTFmLWQ2NGQtNDE3My1hZjliLTEyZWNhYTEwMzBiMyIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sLXF1aWNrc3RhcnRzLTEzNTEwOSIsImFjY291bnROYW1lIjoicXVpY2stc3RhcnRzLXdzLTEzNTEwOSIsIndvcmtzcGFjZUlkIjoiMmQ2NmViOTAtNzFjZi00NGRiLTkxZTMtMDAyNzRjOTYzYWFkIn0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
            " ---> Running in 220e945b1cc9\n",
            " ---> 49f72c325083\n",
            "Step 4/5 : RUN mv '/var/azureml-app/tmp5cqhij2b.py' /var/azureml-app/main.py\n",
            " ---> Running in 3713de5eb01f\n",
            "Current provisioning state of AmlCompute is \"Deleting\"\n",
            "\n",
            " ---> 6254c5259803\n",
            "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
            " ---> Running in 9ed3efd7236f\n",
            " ---> 5488fdb63ce7\n",
            "Successfully built 5488fdb63ce7\n",
            "Successfully tagged hyperdrivelaborpredservice2:latest\n",
            "Starting Docker container...\n",
            "Docker container running.\n",
            "Checking container health...\n",
            "\n",
            "Container Logs:\n",
            "2021-01-17T21:08:44,354498389+00:00 - gunicorn/run \n",
            "2021-01-17T21:08:44,356705367+00:00 - rsyslog/run \n",
            "2021-01-17T21:08:44,362556109+00:00 - iot-server/run \n",
            "2021-01-17T21:08:44,372883206+00:00 - nginx/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-01-17T21:08:44,442171119+00:00 - iot-server/finish 1 0\n",
            "2021-01-17T21:08:44,443373307+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (13)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 41\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-01-17 21:08:45,161 | root | INFO | Starting up app insights client\n",
            "Starting up app insights client\n",
            "2021-01-17 21:08:45,161 | root | INFO | Starting up request id generator\n",
            "Starting up request id generator\n",
            "2021-01-17 21:08:45,161 | root | INFO | Starting up app insight hooks\n",
            "Starting up app insight hooks\n",
            "2021-01-17 21:08:45,161 | root | INFO | Invoking user's init function\n",
            "Invoking user's init function\n",
            "2021-01-17 21:08:45,161 | root | ERROR | User's init function failed\n",
            "User's init function failed\n",
            "2021-01-17 21:08:45,162 | root | ERROR | Encountered Exception Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/aml_blueprint.py\", line 177, in register\n",
            "    main.init()\n",
            "  File \"/var/azureml-app/score.py\", line 11, in init\n",
            "    model = joblib.load(model_path)\n",
            "  File \"/azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 597, in load\n",
            "    with open(filename, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/bestmodel.pkl/7/bestmodel.pkl'\n",
            "\n",
            "Encountered Exception Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/aml_blueprint.py\", line 177, in register\n",
            "    main.init()\n",
            "  File \"/var/azureml-app/score.py\", line 11, in init\n",
            "    model = joblib.load(model_path)\n",
            "  File \"/azureml-envs/azureml_46331db455ceb96309136c030bbd61f1/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 597, in load\n",
            "    with open(filename, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/bestmodel.pkl/7/bestmodel.pkl'\n",
            "\n",
            "Worker exiting (pid: 41)\n",
            "Shutting down: Master\n",
            "Reason: Worker failed to boot.\n",
            "2021-01-17T21:08:45,256958033+00:00 - gunicorn/finish 3 0\n",
            "2021-01-17T21:08:45,258232120+00:00 - Exit code 3 is not normal. Killing image.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:azureml._model_management._util:Error: Container has crashed. Did your init method fail?\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5352e5245734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hyperdrivelaborpredservice2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     71\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_health_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 743\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610834312288
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#send request\r\n",
        "\r\n",
        "import requests\r\n",
        "import json\r\n",
        "from pandas import DataFrame\r\n",
        "\r\n",
        "scoring_uri = service.scoring_uri\r\n",
        "key = 'sRUbXlGvqG2wruJmE7AUhdnixOkzcF2E'\r\n",
        "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key}\r\n",
        "    \r\n",
        "input_string = {'data':[{\"heightwholenum\":67,\"widthWholeNum\":24,\"lift\":0,\"LongCarry\":0,\"itemset_\":0,\"itemset_OTHER\":0,\"itemset_PRESSURE PLATE\":0,\"itemset_PUTTY\":0,\"itemset_SCREW BEADS\":0,\"itemset_SNAP BEADS\":1,\r\n",
        "\"itemset_VINYL BEADS\":0,\"itemset_WOOD BEADS\":0,\"itemset_WRAP AROUND FRAME\":0,\"itemset_WRAP AROUND RUBBER\":0,\"itemset_flush glaze\":0,\"leadmechanic_6\":0,\"leadmechanic_11\":0,\"leadmechanic_62\":0,\"leadmechanic_90\":0,\r\n",
        "\"leadmechanic_118\":1,\"leadmechanic_211\":0,\"leadmechanic_228\":0,\"leadmechanic_OTHER\":0,\"locationtype_0\":0,\"locationtype_1\":0,\"locationtype_2\":0,\"locationtype_4\":0,\"locationtype_5\":0,\"locationtype_6\":0,\r\n",
        "\"locationtype_7\":0,\"locationtype_9\":1,\"locationtype_10\":0,\"locationtype_11\":0,\"locationtype_12\":0,\"locationtype_13\":0,\"framemat_\":0,\"framemat_ALUMINUM\":1,\"framemat_ANDERSEN\":0,\"framemat_OTHER\":0,\r\n",
        "\"framemat_SASH RAIL\":0,\"framemat_VINYL\":0,\"framemat_WOOD\":0,\"framefunc_BOTTOM DH\":0,\"framefunc_BOTTOM SH\":0,\"framefunc_CASEMENT\":0,\"framefunc_CURTAIN WALL\":0,\"framefunc_FIXED\":0,\"framefunc_FLUSH GLAZE\":0,\r\n",
        "\"framefunc_OTHER\":0,\"framefunc_SASH\":0,\"framefunc_SIDELITE\":0,\"framefunc_SLIDER\":0,\"framefunc_TOP DH\":0,\"framefunc_TOP SH\":0,\"framefunc_TRANSOM\":0}]}\r\n",
        "data = json.dumps(input_string)\r\n",
        "\r\n",
        "response = requests.post(scoring_uri, data=data, headers=headers)\r\n",
        "print(response.status_code)\r\n",
        "print(response.elapsed)\r\n",
        "print('Labor Prediction: ' + response.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610834366265
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610654444036
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}